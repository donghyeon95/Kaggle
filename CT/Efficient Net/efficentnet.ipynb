{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c50f01a-72fd-4804-9f54-d77b52d3991f",
   "metadata": {},
   "source": [
    "# [모의 캐글-의료] 흉부 CT 코로나 감염 여부 분류\n",
    "- 이미지 binary 분류 과제\n",
    "- 담당: 이녕민M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, copy, cv2, sys, random\n",
    "# from datetime import datetime, timezone, timedelta\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "# dataset and transformation\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "# display images\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# utils\n",
    "import numpy as np\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954",
   "metadata": {},
   "source": [
    "## Set Arguments & hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9c4250-2257-404f-941d-58eff1e9eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드(seed) 설정\n",
    "\n",
    "RANDOM_SEED = 2022\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "### 데이터 디렉토리 설정 ###\n",
    "DATA_DIR= '/USER/data'\n",
    "NUM_CLS = 2\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0005\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "INPUT_SHAPE = 384\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44807b0-7788-49ec-aff2-c756e4513c5e",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05",
   "metadata": {},
   "source": [
    "#### Train & Validation Set loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04642777-c2e0-439b-9692-f6c571a86521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Dataset split\n",
    "        if self.mode == 'train':\n",
    "            self.db = self.db[:int(len(self.db) * 0.9)]\n",
    "        elif self.mode == 'val':\n",
    "            self.db = self.db[int(len(self.db) * 0.9):]\n",
    "            self.db.reset_index(inplace=True)\n",
    "        else:\n",
    "            print(f'!!! Invalid split {self.mode}... !!!')\n",
    "            \n",
    "        # Transform function\n",
    "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        # (COVID : 1, No : 0)\n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
    "        \n",
    "        return db\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "\n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        return trans_image, data['COVID']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b27520-c82c-4ec8-ae0b-119a79167f09",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b9107b-a316-457e-84a8-9f4fa39754c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75e942d-414e-446c-a4f1-595518eace37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, r=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels * r),\n",
    "            Swish(),\n",
    "            nn.Linear(in_channels * r, in_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.excitation(x)\n",
    "        x = x.view(x.size(0), x.size(1), 1, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e92d4c6-f16b-48c1-80c8-43983a546cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    expand = 6\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n",
    "        super().__init__()\n",
    "        # first MBConv is not using stochastic depth\n",
    "        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels * MBConv.expand, 1, stride=stride, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_channels * MBConv.expand, in_channels * MBConv.expand, kernel_size=kernel_size,\n",
    "                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*MBConv.expand),\n",
    "            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        self.se = SEBlock(in_channels * MBConv.expand, se_scale)\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*MBConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # stochastic depth\n",
    "        if self.training:\n",
    "            if not torch.bernoulli(self.p):\n",
    "                return x\n",
    "\n",
    "        x_shortcut = x\n",
    "        x_residual = self.residual(x)\n",
    "        x_se = self.se(x_residual)\n",
    "\n",
    "        x = x_se * x_residual\n",
    "        x = self.project(x)\n",
    "\n",
    "        if self.shortcut:\n",
    "            x= x_shortcut + x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45fb2203-983a-4a6e-8a8e-eadb3b3c80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SepConv(nn.Module):\n",
    "    expand = 1\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n",
    "        super().__init__()\n",
    "        # first SepConv is not using stochastic depth\n",
    "        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * SepConv.expand, in_channels * SepConv.expand, kernel_size=kernel_size,\n",
    "                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*SepConv.expand),\n",
    "            nn.BatchNorm2d(in_channels * SepConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        self.se = SEBlock(in_channels * SepConv.expand, se_scale)\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*SepConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # stochastic depth\n",
    "        if self.training:\n",
    "            if not torch.bernoulli(self.p):\n",
    "                return x\n",
    "\n",
    "        x_shortcut = x\n",
    "        x_residual = self.residual(x)\n",
    "        x_se = self.se(x_residual)\n",
    "\n",
    "        x = x_se * x_residual\n",
    "        x = self.project(x)\n",
    "\n",
    "        if self.shortcut:\n",
    "            x= x_shortcut + x\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "685e0b73-f323-40ea-b372-6c1d607618a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes=2, width_coef=1., depth_coef=1., scale=1., dropout=0.2, se_scale=4, stochastic_depth=False, p=0.5):\n",
    "        super().__init__()\n",
    "        channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n",
    "        repeats = [1, 2, 2, 3, 3, 4, 1]\n",
    "        strides = [1, 2, 2, 2, 1, 2, 1]\n",
    "        kernel_size = [3, 3, 5, 3, 5, 5, 3]\n",
    "        depth = depth_coef\n",
    "        width = width_coef\n",
    "\n",
    "        channels = [int(x*width) for x in channels]\n",
    "        repeats = [int(x*depth) for x in repeats]\n",
    "\n",
    "        # stochastic depth\n",
    "        if stochastic_depth:\n",
    "            self.p = p\n",
    "            self.step = (1 - 0.5) / (sum(repeats) - 1)\n",
    "        else:\n",
    "            self.p = 1\n",
    "            self.step = 0\n",
    "\n",
    "\n",
    "        # efficient net\n",
    "        self.upsample = nn.Upsample(scale_factor=scale, mode='bilinear', align_corners=False)\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(3, channels[0],3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(channels[0], momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.stage2 = self._make_Block(SepConv, repeats[0], channels[0], channels[1], kernel_size[0], strides[0], se_scale)\n",
    "\n",
    "        self.stage3 = self._make_Block(MBConv, repeats[1], channels[1], channels[2], kernel_size[1], strides[1], se_scale)\n",
    "\n",
    "        self.stage4 = self._make_Block(MBConv, repeats[2], channels[2], channels[3], kernel_size[2], strides[2], se_scale)\n",
    "\n",
    "        self.stage5 = self._make_Block(MBConv, repeats[3], channels[3], channels[4], kernel_size[3], strides[3], se_scale)\n",
    "\n",
    "        self.stage6 = self._make_Block(MBConv, repeats[4], channels[4], channels[5], kernel_size[4], strides[4], se_scale)\n",
    "\n",
    "        self.stage7 = self._make_Block(MBConv, repeats[5], channels[5], channels[6], kernel_size[5], strides[5], se_scale)\n",
    "\n",
    "        self.stage8 = self._make_Block(MBConv, repeats[6], channels[6], channels[7], kernel_size[6], strides[6], se_scale)\n",
    "\n",
    "        self.stage9 = nn.Sequential(\n",
    "            nn.Conv2d(channels[7], channels[8], 1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(channels[8], momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        ) \n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear = nn.Linear(channels[8], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x)\n",
    "        x = self.stage7(x)\n",
    "        x = self.stage8(x)\n",
    "        x = self.stage9(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _make_Block(self, block, repeats, in_channels, out_channels, kernel_size, stride, se_scale):\n",
    "        strides = [stride] + [1] * (repeats - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(in_channels, out_channels, kernel_size, stride, se_scale, self.p))\n",
    "            in_channels = out_channels\n",
    "            self.p -= self.step\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def efficientnet_b0(num_classes=2):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.0, depth_coef=1.0, scale=1.0,dropout=0.2, se_scale=4)\n",
    "\n",
    "def efficientnet_b1(num_classes=2):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.0, depth_coef=1.1, scale=240/224, dropout=0.2, se_scale=4)\n",
    "\n",
    "def efficientnet_b2(num_classes=2):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.1, depth_coef=1.2, scale=260/224., dropout=0.3, se_scale=4)\n",
    "\n",
    "def efficientnet_b3(num_classes=2):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.2, depth_coef=1.4, scale=300/224, dropout=0.3, se_scale=4)\n",
    "\n",
    "def efficientnet_b4(num_classes=2):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.4, depth_coef=1.8, scale=380/224, dropout=0.4, se_scale=4)\n",
    "\n",
    "def efficientnet_b5(num_classes=2):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.6, depth_coef=2.2, scale=456/224, dropout=0.4, se_scale=4)\n",
    "\n",
    "def efficientnet_b6(num_classes=2):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.8, depth_coef=2.6, scale=528/224, dropout=0.5, se_scale=4)\n",
    "\n",
    "def efficientnet_b7(num_classes=2):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=2.0, depth_coef=3.1, scale=600/224, dropout=0.5, se_scale=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71477d10-e304-49ec-acf8-76f62bd483a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (upsample): Upsample(scale_factor=1.0, mode=bilinear)\n",
       "  (stage1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (stage2): Sequential(\n",
       "    (0): SepConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage3): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "        (4): BatchNorm2d(96, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=576, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=576, out_features=144, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage4): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=576, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=576, out_features=144, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(40, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (4): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=240, out_features=960, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=960, out_features=240, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(40, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage5): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "        (4): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=240, out_features=960, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=960, out_features=240, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (4): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=480, out_features=1920, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=1920, out_features=480, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (4): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=480, out_features=1920, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=1920, out_features=480, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage6): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (4): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=480, out_features=1920, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=1920, out_features=480, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (4): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=672, out_features=2688, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=2688, out_features=672, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (4): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=672, out_features=2688, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=2688, out_features=672, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage7): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (4): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=672, out_features=2688, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=2688, out_features=672, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage8): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage9): Sequential(\n",
       "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1280, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    (2): Swish(\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear): Linear(in_features=1280, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = efficientnet_b0().to(DEVICE)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d056905-1f77-4579-a260-07bb1056f6db",
   "metadata": {},
   "source": [
    "## Utils\n",
    "### EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "    \n",
    "    Attributes:\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가, 감소 시 0으로 리셋\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int)-> None:\n",
    "        self.patience = patience\n",
    "\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "        self.save_model = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        \"\"\"Early stopping 여부 판단\"\"\"  \n",
    "\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "            return None\n",
    "\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "                \n",
    "        elif loss <= self.min_loss:\n",
    "            self.patience_counter = 0\n",
    "            self.save_model = True\n",
    "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "        \n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaffd8d-b025-42c1-8dd8-69529487389e",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5faaac1b-64c3-4659-82de-d4309502f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "\n",
    "# get current lr\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "# calculate the metric per mini-batch\n",
    "def metric_batch(output, target):\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects\n",
    "\n",
    "\n",
    "# calculate the loss per mini-batch\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss_b = loss_func(output, target)\n",
    "    metric_b = metric_batch(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss_b.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    return loss_b.item(), metric_b\n",
    "\n",
    "\n",
    "# calculate the loss per epochs\n",
    "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "        output = model(xb)\n",
    "\n",
    "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "\n",
    "        if sanity_check is True:\n",
    "            break\n",
    "\n",
    "    loss = running_loss / len_data\n",
    "    metric = running_metric / len_data\n",
    "    return loss, metric\n",
    "\n",
    "\n",
    "# function to start training\n",
    "def train_val(model, params):\n",
    "    num_epochs=params['num_epochs']\n",
    "    loss_func=params['loss_func']\n",
    "    opt=params['optimizer']\n",
    "    train_dl=params['train_dl']\n",
    "    val_dl=params['val_dl']\n",
    "    sanity_check=params['sanity_check']\n",
    "    lr_scheduler=params['lr_scheduler']\n",
    "    path2weights=params['path2weights']\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), path2weights)\n",
    "            print('Copied best model weights!')\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "        if current_lr != get_lr(opt):\n",
    "            print('Loading best model weights!')\n",
    "            model.load_state_dict(best_model_wts)\n",
    "\n",
    "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "        \n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ef6c6-0936-41fb-926b-db4a363d72ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e087da-a0c2-403d-a6ac-2d8c7290706a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2aca506-d168-4c9f-8eca-5cdecb122961",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33678d90-a254-48d5-bf09-2a817eeafea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_metric_fn(y_pred, y_answer):\n",
    "    \"\"\" 성능을 반환하는 함수\"\"\"\n",
    "    \n",
    "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
    "    accuracy = accuracy_score(y_answer, y_pred)\n",
    "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729c079-9d85-49ce-857f-320b0c56a3a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train\n",
    "### 학습을 위한 객체 선언train_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19610a4-ad7c-44a0-80cd-9734b5015100",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Loading val dataset..\n",
      "Train set samples: 581 Val set samples: 65\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE)\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e1f27b5-192f-4fd4-904c-02ebd1d51ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train = {\n",
    "    'num_epochs':30,\n",
    "    'optimizer':opt,\n",
    "    'loss_func':loss_func,\n",
    "    'train_dl':train_dataloader,\n",
    "    'val_dl':validation_dataloader,\n",
    "    'sanity_check':False,\n",
    "    'lr_scheduler':lr_scheduler,\n",
    "    'path2weights':'/USER/weights.pt',\n",
    "}\n",
    "\n",
    "# check the directory to save weights.pt\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSerror:\n",
    "        print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4",
   "metadata": {},
   "source": [
    "#### Load model and other utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29, current lr= 0.01\n",
      "Copied best model weights!\n",
      "train loss: 0.664454, val loss: 0.613440, accuracy: 69.23, time: 0.8659 min\n",
      "----------\n",
      "Epoch 1/29, current lr= 0.01\n",
      "train loss: 0.650252, val loss: 0.695360, accuracy: 58.46, time: 1.7025 min\n",
      "----------\n",
      "Epoch 2/29, current lr= 0.01\n",
      "train loss: 0.580368, val loss: 0.744850, accuracy: 69.23, time: 2.5157 min\n",
      "----------\n",
      "Epoch 3/29, current lr= 0.01\n",
      "Copied best model weights!\n",
      "train loss: 0.620160, val loss: 0.579208, accuracy: 69.23, time: 3.3688 min\n",
      "----------\n",
      "Epoch 4/29, current lr= 0.01\n",
      "train loss: 0.626349, val loss: 0.792640, accuracy: 52.31, time: 4.1792 min\n",
      "----------\n",
      "Epoch 5/29, current lr= 0.01\n",
      "train loss: 0.640918, val loss: 0.839004, accuracy: 69.23, time: 5.0075 min\n",
      "----------\n",
      "Epoch 6/29, current lr= 0.01\n",
      "train loss: 0.608808, val loss: 0.675876, accuracy: 66.15, time: 5.8141 min\n",
      "----------\n",
      "Epoch 7/29, current lr= 0.01\n",
      "train loss: 0.573485, val loss: 0.895571, accuracy: 60.00, time: 6.6659 min\n",
      "----------\n",
      "Epoch 8/29, current lr= 0.01\n",
      "train loss: 0.548532, val loss: 0.646981, accuracy: 60.00, time: 7.4921 min\n",
      "----------\n",
      "Epoch 9/29, current lr= 0.01\n",
      "Copied best model weights!\n",
      "train loss: 0.559162, val loss: 0.537262, accuracy: 73.85, time: 8.3484 min\n",
      "----------\n",
      "Epoch 10/29, current lr= 0.01\n",
      "train loss: 0.541117, val loss: 0.800092, accuracy: 55.38, time: 9.2144 min\n",
      "----------\n",
      "Epoch 11/29, current lr= 0.01\n",
      "train loss: 0.554435, val loss: 0.692667, accuracy: 56.92, time: 10.0525 min\n",
      "----------\n",
      "Epoch 12/29, current lr= 0.01\n",
      "train loss: 0.556736, val loss: 0.643835, accuracy: 61.54, time: 10.9075 min\n",
      "----------\n",
      "Epoch 13/29, current lr= 0.01\n",
      "train loss: 0.525573, val loss: 0.558037, accuracy: 70.77, time: 11.7425 min\n",
      "----------\n",
      "Epoch 14/29, current lr= 0.01\n",
      "train loss: 0.534579, val loss: 0.584635, accuracy: 64.62, time: 12.5423 min\n",
      "----------\n",
      "Epoch 15/29, current lr= 0.01\n",
      "train loss: 0.475549, val loss: 0.562350, accuracy: 75.38, time: 13.3625 min\n",
      "----------\n",
      "Epoch 16/29, current lr= 0.01\n",
      "train loss: 0.476105, val loss: 0.824193, accuracy: 58.46, time: 14.1956 min\n",
      "----------\n",
      "Epoch 17/29, current lr= 0.01\n",
      "Copied best model weights!\n",
      "train loss: 0.512939, val loss: 0.477344, accuracy: 80.00, time: 15.0156 min\n",
      "----------\n",
      "Epoch 18/29, current lr= 0.01\n",
      "train loss: 0.525069, val loss: 0.543823, accuracy: 69.23, time: 15.8592 min\n",
      "----------\n",
      "Epoch 19/29, current lr= 0.01\n",
      "train loss: 0.515726, val loss: 0.624003, accuracy: 61.54, time: 16.7140 min\n",
      "----------\n",
      "Epoch 20/29, current lr= 0.01\n",
      "Copied best model weights!\n",
      "train loss: 0.490568, val loss: 0.458549, accuracy: 70.77, time: 17.5787 min\n",
      "----------\n",
      "Epoch 21/29, current lr= 0.01\n",
      "train loss: 0.447647, val loss: 0.590008, accuracy: 66.15, time: 18.4075 min\n",
      "----------\n",
      "Epoch 22/29, current lr= 0.01\n",
      "train loss: 0.419704, val loss: 0.477510, accuracy: 76.92, time: 19.2342 min\n",
      "----------\n",
      "Epoch 23/29, current lr= 0.01\n",
      "train loss: 0.407437, val loss: 0.614527, accuracy: 72.31, time: 20.0558 min\n",
      "----------\n",
      "Epoch 24/29, current lr= 0.01\n",
      "train loss: 0.377836, val loss: 0.495426, accuracy: 72.31, time: 20.8857 min\n",
      "----------\n",
      "Epoch 25/29, current lr= 0.01\n",
      "train loss: 0.361017, val loss: 0.637212, accuracy: 76.92, time: 21.7228 min\n",
      "----------\n",
      "Epoch 26/29, current lr= 0.01\n",
      "train loss: 0.491684, val loss: 0.736117, accuracy: 67.69, time: 22.5692 min\n",
      "----------\n",
      "Epoch 27/29, current lr= 0.01\n",
      "train loss: 0.366204, val loss: 0.523888, accuracy: 70.77, time: 23.4042 min\n",
      "----------\n",
      "Epoch 28/29, current lr= 0.01\n",
      "train loss: 0.352262, val loss: 0.539632, accuracy: 70.77, time: 24.2408 min\n",
      "----------\n",
      "Epoch 29/29, current lr= 0.01\n",
      "train loss: 0.322336, val loss: 0.772740, accuracy: 72.31, time: 25.0741 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b881024-3921-4c2c-b9ec-e6b23c4f5ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (upsample): Upsample(scale_factor=1.0, mode=bilinear)\n",
       "  (stage1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (stage2): Sequential(\n",
       "    (0): SepConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage3): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "        (4): BatchNorm2d(96, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=576, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=576, out_features=144, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage4): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=576, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=576, out_features=144, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(40, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (4): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=240, out_features=960, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=960, out_features=240, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(40, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage5): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "        (4): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=240, out_features=960, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=960, out_features=240, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (4): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=480, out_features=1920, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=1920, out_features=480, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (4): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=480, out_features=1920, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=1920, out_features=480, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage6): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (4): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=480, out_features=1920, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=1920, out_features=480, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (4): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=672, out_features=2688, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=2688, out_features=672, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (4): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=672, out_features=2688, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=2688, out_features=672, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage7): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (4): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=672, out_features=2688, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=2688, out_features=672, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage8): Sequential(\n",
       "    (0): MBConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (2): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (4): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (5): Swish(\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (squeeze): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (excitation): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Swish(\n",
       "            (sigmoid): Sigmoid()\n",
       "          )\n",
       "          (2): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (stage9): Sequential(\n",
       "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1280, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    (2): Swish(\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear): Linear(in_features=1280, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724",
   "metadata": {},
   "source": [
    "### epoch 단위 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53514a-e83f-4795-9589-640f26cc2993",
   "metadata": {},
   "source": [
    "## Inference\n",
    "### 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_PATH = '/USER/weights.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_dir, input_shape):\n",
    "        self.data_dir = data_dir\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # Loading dataset\n",
    "        self.db = self.data_loader()\n",
    "        \n",
    "        # Transform function\n",
    "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
    "                                             transforms.ToTensor(),\n",
    "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading test dataset..')\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
    "            sys.exit()\n",
    "        \n",
    "        db = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n",
    "        return db\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "        \n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(os.path.join(self.data_dir,'test',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        return trans_image, data['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset..\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "test_dataset = TestDataset(data_dir=DATA_DIR, input_shape=INPUT_SHAPE)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58",
   "metadata": {},
   "source": [
    "### 추론 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6918, -1.8749],\n",
      "        [-0.5390,  0.5082],\n",
      "        [ 0.2765, -0.3568],\n",
      "        [ 0.2024, -0.2421],\n",
      "        [ 1.6966, -1.8693],\n",
      "        [-1.4069,  1.4542],\n",
      "        [-0.8982,  0.9215],\n",
      "        [-0.4615,  0.4530],\n",
      "        [-1.1132,  1.1124],\n",
      "        [-2.1899,  2.2501],\n",
      "        [ 0.5393, -0.6527],\n",
      "        [-0.3677,  0.3171],\n",
      "        [ 1.9206, -2.1095],\n",
      "        [-2.2694,  2.3257],\n",
      "        [ 0.2826, -0.3225],\n",
      "        [-0.6058,  0.5725],\n",
      "        [ 0.7308, -0.8579],\n",
      "        [ 1.8173, -2.0052],\n",
      "        [ 0.4734, -0.5575],\n",
      "        [ 0.9776, -1.1158],\n",
      "        [ 1.5331, -1.6893],\n",
      "        [ 0.6091, -0.7316],\n",
      "        [ 0.2596, -0.3673],\n",
      "        [ 0.3473, -0.4526],\n",
      "        [-2.1621,  2.2130],\n",
      "        [ 1.9018, -2.0977],\n",
      "        [ 2.0365, -2.2444],\n",
      "        [-1.1813,  1.1881],\n",
      "        [-1.1768,  1.1931],\n",
      "        [-1.4749,  1.5211],\n",
      "        [-1.0974,  1.1264],\n",
      "        [-1.6339,  1.6794]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:04,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1464e+00,  1.1425e+00],\n",
      "        [ 1.2576e+00, -1.3883e+00],\n",
      "        [ 1.0273e+00, -1.1743e+00],\n",
      "        [-1.1194e+00,  1.1565e+00],\n",
      "        [-1.9913e+00,  2.0472e+00],\n",
      "        [ 3.6106e-01, -4.6982e-01],\n",
      "        [-1.4626e+00,  1.5028e+00],\n",
      "        [ 1.1184e+00, -1.2558e+00],\n",
      "        [-4.0062e-01,  4.1199e-01],\n",
      "        [-7.8322e-01,  7.8205e-01],\n",
      "        [ 3.9874e-01, -4.6899e-01],\n",
      "        [-1.7495e+00,  1.7997e+00],\n",
      "        [ 1.0524e-03, -1.1613e-02],\n",
      "        [-8.5967e-02,  7.7742e-03],\n",
      "        [ 3.3253e-01, -4.0868e-01],\n",
      "        [ 2.1487e+00, -2.3573e+00],\n",
      "        [-3.5197e-01,  3.0610e-01],\n",
      "        [ 8.3114e-01, -9.6343e-01],\n",
      "        [-2.0569e-02, -2.3301e-03],\n",
      "        [-1.4927e+00,  1.5379e+00],\n",
      "        [-4.5199e-01,  4.3604e-01],\n",
      "        [-3.2067e-01,  2.8043e-01],\n",
      "        [-2.4360e-01,  2.4568e-01],\n",
      "        [ 5.1108e-01, -6.0871e-01],\n",
      "        [-2.8666e-01,  2.4201e-01],\n",
      "        [-1.2186e+00,  1.2592e+00],\n",
      "        [ 2.1417e+00, -2.3482e+00],\n",
      "        [ 4.5372e-02, -1.2490e-01],\n",
      "        [-2.4110e+00,  2.4890e+00],\n",
      "        [ 1.6924e+00, -1.8577e+00],\n",
      "        [ 8.9873e-01, -1.0204e+00],\n",
      "        [-7.3830e-01,  7.1740e-01]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:06,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2314e+00,  1.2465e+00],\n",
      "        [-2.3759e+00,  2.4392e+00],\n",
      "        [-1.9219e+00,  1.9690e+00],\n",
      "        [-6.8710e-02,  1.9245e-03],\n",
      "        [-8.5569e-01,  8.6423e-01],\n",
      "        [ 1.5617e+00, -1.7256e+00],\n",
      "        [ 6.0661e-01, -7.2007e-01],\n",
      "        [ 4.6999e-01, -5.4981e-01],\n",
      "        [ 7.5518e-01, -8.6590e-01],\n",
      "        [ 1.2328e-01, -1.9827e-01],\n",
      "        [-1.1295e+00,  1.1387e+00],\n",
      "        [ 2.2269e+00, -2.4442e+00],\n",
      "        [ 1.5864e+00, -1.7574e+00],\n",
      "        [ 6.9150e-01, -8.1044e-01],\n",
      "        [ 6.8281e-01, -7.7715e-01],\n",
      "        [-1.5081e+00,  1.5622e+00],\n",
      "        [-1.1417e+00,  1.0984e+00],\n",
      "        [-8.1685e-01,  8.1573e-01],\n",
      "        [ 2.0958e+00, -2.3034e+00],\n",
      "        [-1.2237e+00,  1.2192e+00],\n",
      "        [ 6.9618e-01, -7.9734e-01],\n",
      "        [-1.4014e+00,  1.4266e+00],\n",
      "        [ 1.4861e-02, -7.3486e-02],\n",
      "        [-8.5214e-01,  8.5790e-01],\n",
      "        [ 9.5761e-01, -1.0914e+00],\n",
      "        [-1.4880e-01,  1.3040e-01],\n",
      "        [-1.0074e+00,  9.8184e-01],\n",
      "        [ 4.1943e-01, -5.3490e-01],\n",
      "        [-2.1052e+00,  2.1478e+00],\n",
      "        [-9.9719e-01,  1.0269e+00],\n",
      "        [ 2.2329e+00, -2.4536e+00],\n",
      "        [ 1.3885e+00, -1.5575e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:06,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3598,  2.4416],\n",
      "        [-0.7360,  0.7159],\n",
      "        [-1.2377,  1.2692],\n",
      "        [-0.9345,  0.9560]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])\n",
    "\n",
    "# Prediction\n",
    "file_lst = []\n",
    "pred_lst = []\n",
    "prob_lst = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (img, file_num) in tqdm(enumerate(test_dataloader)):\n",
    "        img = img.to(DEVICE)\n",
    "        pred = model(img)\n",
    "        print(pred)\n",
    "        file_lst.extend(list(file_num))\n",
    "        pred_lst.extend(pred.argmax(dim=1).tolist())\n",
    "        prob_lst.extend(pred[:, 1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056169d1-64a8-4b81-8daf-722b029cf2b9",
   "metadata": {},
   "source": [
    "### 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'file_name':file_lst, 'COVID':pred_lst})\n",
    "# df.sort_values(by=['file_name'], inplace=True)\n",
    "df.to_csv('/USER/prediction2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5b7ae-2810-42c4-9335-ae1c6b6e2746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
